In this we will implement and compare the following different KNN variants
1) LSH
2) KD-tree
3) Naive version of KNN

We will vary the dataset size $N$, number of dimensions $D$ to do training and testing time and memory comparison for finding $K$ nearest neighbours.

Now, in a 2d randomly generated dataset visually show how many of the $K$ closest neighbours appx. $KNN$ methods miss out due to their approximate nature. 

We will also show the partitions in the 2d space.
